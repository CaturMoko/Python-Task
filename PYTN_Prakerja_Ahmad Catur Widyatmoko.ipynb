{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Exploration**\n",
    "\n",
    "Importing the data and taking a quick look on the data to get basic understanding about the problem that we are dealing with  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/heart.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.float\", \"{:.2f}\".format)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target.value_counts().hvplot.bar(\n",
    "    title=\"Heart Disease Count\", xlabel='Heart Disease', ylabel='Count', \n",
    "    width=500, height=350\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_val = []\n",
    "continous_val = []\n",
    "for column in data.columns:\n",
    "    if len(data[column].unique()) <= 10:\n",
    "        categorical_val.append(column)\n",
    "    else:\n",
    "        continous_val.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_disease = data.loc[data['target']==1, 'sex'].value_counts().hvplot.bar(alpha=0.4) \n",
    "no_disease = data.loc[data['target']==0, 'sex'].value_counts().hvplot.bar(alpha=0.4) \n",
    "\n",
    "(no_disease * have_disease).opts(\n",
    "    title=\"Heart Disease by Sex\", xlabel='Sex', ylabel='Count',\n",
    "    width=500, height=450, legend_cols=2, legend_position='top_right'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_disease = data.loc[data['target']==1, 'cp'].value_counts().hvplot.bar(alpha=0.4) \n",
    "no_disease = data.loc[data['target']==0, 'cp'].value_counts().hvplot.bar(alpha=0.4) \n",
    "\n",
    "(no_disease * have_disease).opts(\n",
    "    title=\"Heart Disease by Chest Pain Type\", xlabel='Chest Pain Type', ylabel='Count',\n",
    "    width=500, height=450, legend_cols=2, legend_position='top_right'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_disease = data.loc[data['target']==1, 'fbs'].value_counts().hvplot.bar(alpha=0.4) \n",
    "no_disease = data.loc[data['target']==0, 'fbs'].value_counts().hvplot.bar(alpha=0.4) \n",
    "\n",
    "(no_disease * have_disease).opts(\n",
    "    title=\"Heart Disease by fasting blood sugar\", xlabel='fasting blood sugar > 120 mg/dl (1 = true; 0 = false)', \n",
    "    ylabel='Count', width=500, height=450, legend_cols=2, legend_position='top_right'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_disease = data.loc[data['target']==1, 'restecg'].value_counts().hvplot.bar(alpha=0.4) \n",
    "no_disease = data.loc[data['target']==0, 'restecg'].value_counts().hvplot.bar(alpha=0.4) \n",
    "\n",
    "(no_disease * have_disease).opts(\n",
    "    title=\"Heart Disease by resting electrocardiographic results\", xlabel='resting electrocardiographic results', \n",
    "    ylabel='Count', width=500, height=450, legend_cols=2, legend_position='top_right'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, column in enumerate(categorical_val, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    data[data[\"target\"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)\n",
    "    data[data[\"target\"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.xlabel(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, column in enumerate(continous_val, 1):\n",
    "    plt.subplot(3, 2, i)\n",
    "    data[data[\"target\"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)\n",
    "    data[data[\"target\"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.xlabel(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "# Scatter plot with postivie examples\n",
    "plt.scatter(data.age[data.target==1],\n",
    "            data.thalach[data.target==1],\n",
    "            c=\"salmon\")\n",
    "\n",
    "# Scatter plot with negative examples\n",
    "plt.scatter(data.age[data.target==0],\n",
    "            data.thalach[data.target==0],\n",
    "            c=\"lightblue\")\n",
    "\n",
    "# Add some legend to the fig\n",
    "plt.title(\"Heart Disease in function of Age and Max Heart Rate\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Max Heart Rate\")\n",
    "plt.legend([\"Disease\", \"No Disease\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Corelation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data.corr()\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax = sns.heatmap(corr_matrix,\n",
    "                 annot=True,\n",
    "                 linewidths=0.5,\n",
    "                 fmt=\".2f\",\n",
    "                 cmap=\"YlGnBu\");\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('target', axis=1).corrwith(data.target).hvplot.barh(\n",
    "    width=600, height=400, \n",
    "    title=\"Correlation between Heart Disease and Numeric Features\", \n",
    "    ylabel='Correlation', xlabel='Numerical Features',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_val.remove('target')\n",
    "dataset = pd.get_dummies(data, columns = categorical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "s_sc = StandardScaler()\n",
    "col_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "dataset[col_to_scale] = s_sc.fit_transform(dataset[col_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start to Create Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset.drop('target', axis=1)\n",
    "y = dataset.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regresion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = accuracy_score(y_test, lr_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, lr_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df = pd.DataFrame(data=[[\"Logistic Regression\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(knn_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(knn_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = accuracy_score(y_test, knn_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, knn_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"K-nearest neighbors\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svm_clf = SVC(kernel='rbf', gamma=0.1, C=1.0)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = accuracy_score(y_test, svm_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, svm_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Support Vector Machine\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decission Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = accuracy_score(y_test, tree_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, tree_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Decision Tree Classifier\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = accuracy_score(y_test, rf_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, rf_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Random Forest Classifier\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion : It looks that Support Vector Machine algorithm achieved the highest testing accuracy to predict the heart disease compared to other algorithms**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
